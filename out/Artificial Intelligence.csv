,name,f,p,r,text
0,TextRank,0.38561356716149925,0.3813559322033898,0.3901734104046243,"In computer science,  artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Artificial intelligence can be classified into three different types of systems: analytical, human-inspired, and humanized artificial intelligence. IBM has created its own artificial intelligence computer, the IBM Watson, which has beaten human intelligence (at some levels). Musk also funds companies developing artificial intelligence such as Google DeepMind and Vicarious to ""just keep an eye on what's going on with artificial intelligence. A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. Turing proposed that ""if a human could not distinguish between responses from a machine and a human, the machine could be considered ""intelligent"". ""robotics"" or ""machine learning""), the use of particular tools (""logic"" or artificial neural networks), or deep philosophical differences. Machine consciousness, sentience and mind+If an AI system replicates all key aspects of human intelligence, will that system also be sentient—will it have a mind which has conscious experiences? Problems+The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The Handbook of Artificial Intelligence Volume Ⅰ by Avron Barr and Edward A. Feigenbaum (Stanford University)+""Artificial Intelligence"". Symbolic+When access to digital computers became possible in the middle 1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. Can a machine solve any problem that a human being can solve using intelligence? A few of the most long standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying psychology or neurobiology? Some cognitive architectures are custom-built to solve a narrow problem; others, such as Soar, are designed to mimic human cognition and to provide insight into general intelligence. Artificial neural networks+Neural networks, or neural nets, were inspired by the architecture of neurons in the human brain. In AGI research, some scholars caution against over-reliance on statistical learning, and argue that continuing research into GOFAI will still be necessary to attain general intelligence. The development of full artificial intelligence could spell the end of the human race. Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. Analytical AI has only characteristics consistent with cognitive intelligence; generating cognitive representation of the world and using learning based on past experience to inform future decisions. The field was founded on the claim that human intelligence ""can be so precisely described that a machine can be made to simulate it"". Finance and economics+Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. Artificial neural networks are an example of soft computing—they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Human-inspired AI has elements from cognitive and emotional intelligence; understanding human emotions, in addition to cognitive elements, and considering them in their decision making. Banks use artificial intelligence systems today to organize operations, maintain book-keeping, invest in stocks, and manage properties. Deep feedforward neural networks+Deep learning is any artificial neural network that can learn a long chain of causal links. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. There are many competitions and prizes, such as the Imagenet Challenge, to promote research in artificial intelligence."
1,Gensim,0.3719378010068642,0.3347763347763348,0.6705202312138728,"Colloquially, the term ""artificial intelligence"" is used to describe machines that mimic ""cognitive"" functions that humans associate with other human minds, such as ""learning"" and ""problem solving"".As machines become increasingly capable, tasks considered to require ""intelligence"" are often removed from the definition of AI, a phenomenon known as the AI effect.
Modern machine capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems (such as chess and Go), autonomously operating cars, intelligent routing in content delivery networks, and military simulations.
Analytical AI has only characteristics consistent with cognitive intelligence; generating cognitive representation of the world and using learning based on past experience to inform future decisions.
""robotics"" or ""machine learning""), the use of particular tools (""logic"" or artificial neural networks), or deep philosophical differences.
Subfields have also been based on social factors (particular institutions or the work of particular researchers).The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.
Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics.
This raises philosophical arguments about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence which are issues that have been explored by myth, fiction and philosophy since antiquity.
Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.
The success was due to increasing computational power (see Moore's law), greater emphasis on solving specific problems, new ties between AI and other fields (such as statistics, economics and mathematics), and a commitment by researchers to mathematical methods and scientific standards.
For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding a pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered in turn.The earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): ""If an otherwise healthy adult has a fever, then they may have influenza"".
Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.
As with the related problem of sub-symbolic reasoning, it is hoped that situated AI, computational intelligence, or statistical AI will provide ways to represent this kind of knowledge.
Machine learning (ML), a fundamental concept of AI research since the field's inception, is the study of computer algorithms that improve automatically through experience.Unsupervised learning is the ability to find patterns in a stream of input, without requiring a human to label the inputs first.
Moravec's paradox generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after Hans Moravec, who stated in 1988 that ""it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility"".
Many researchers predict that such ""narrow AI"" work in different individual domains will eventually be incorporated into a machine with artificial general intelligence (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas.
Besides transfer learning, hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to ""slurp up"" a comprehensive knowledge base from the entire unstructured Web. Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, ""Master Algorithm"" could lead to AGI.
Finally, a few ""emergent"" approaches look to simulating human intelligence extremely closely, and believe that anthropomorphic features like an artificial brain or simulated child development may someday reach a critical point where general intelligence emerges.Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do.
For example, even specific straightforward tasks, like machine translation, require that a machine read and write in both languages (NLP), follow the author's argument (reason), know what is being talked about (knowledge), and faithfully reproduce the author's original intent (social intelligence).
Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.
Economist Herbert Simon and Allen Newell studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as cognitive science, operations research and management science.
Unlike Simon and Newell, John McCarthy felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem-solving, regardless whether people used the same algorithms.
Researchers at MIT (such as Marvin Minsky and Seymour Papert) found that solving difficult problems in vision and natural language processing required ad-hoc solutions—they argued that there was no simple and general principle (like logic) that would capture all the aspects of intelligent behavior.
AI researchers have devised a number of powerful tools to solve these problems using methods from probability theory and economics.Bayesian networks are a very general tool that can be used for a large number of problems: reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks).
In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.The study of non-learning artificial neural networks began in the decade before the field of AI research was founded, in the work of Walter Pitts and Warren McCullouch.
The most common areas of competition include general machine intelligence, conversational behavior, data-mining, robotic cars, and robot soccer as well as conventional games.The ""imitation game"" (an interpretation of the 1950 Turing test that assesses whether a computer can imitate a human) is nowadays considered too exploitable to be a meaningful benchmark.
A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer.Proposed ""universal intelligence"" tests aim to compare how well machines, humans, and even non-human animals perform on problem sets that are generic as possible.
Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google search), online assistants (such as Siri), image recognition in photographs, spam filtering, predicting flight delays, prediction of judicial decisions and targeting online advertisements.With social media sites overtaking TV as a source for news for young people and news organizations increasingly reliant on social media platforms for generating distribution, major publishers now use artificial intelligence (AI) technology to post stories more effectively and generate higher volumes of traffic.
Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence."
2,K-mean-8,0.002908326561869028,0.03125,0.002886002886002886,"Subfields have also been based on social factors (particular institutions or the work of particular researchers).The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects. The next few years would later be called an ""AI winter"", a period when obtaining funding for AI projects was difficult. Definitions+Computer science defines AI research as the study of ""intelligent agents"": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Learners also work on the basis of ""Occam's razor"": The simplest theory that explains the data is the likeliest. Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is. A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. A real-world example is that, unlike humans, current image classifiers don't determine the spatial relationship between components of the picture; instead, they learn abstract patterns of pixels that humans are oblivious to, but that linearly correlate with images of certain types of real objects. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. The traits described below have received the most attention. Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific. Critics note that the shift from GOFAI to statistical learning is often also a shift away from Explainable AI. The simplest intelligent agents are programs that solve specific problems. An agent that solves a specific problem can use any approach that works—some agents are symbolic and logical, some are sub-symbolic artificial neural networks and others may use new approaches. The paradigm also gives researchers a common language to communicate with other fields—such as decision theory and economics—that also use concepts of abstract agents. Some cognitive architectures are custom-built to solve a narrow problem; others, such as Soar, are designed to mimic human cognition and to provide insight into general intelligence. Search and optimization+Many problems in AI can be solved in theory by intelligently searching through many possible solutions: Reasoning can be reduced to performing a search. Some researchers consider NPC AI in games to be a ""solved problem"" for most production tasks. Audit+For financial statements audit, AI makes continuous audit possible. Art+Artificial Intelligence has inspired numerous creative applications including its usage to produce visual art. Can a machine solve any problem that a human being can solve using intelligence? Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at ""high risk"" of potential automation, while an OECD report classifies only 9% of U.S. jobs as ""high risk"". Ethical machines+Machines with intelligence have the potential to use their intelligence to prevent harm and minimize the risks; they may have the ability to use ethical reasoning to better choose their actions in the world. In all cases, only human beings have engaged in ethical reasoning. Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. This idea, called transhumanism, which has roots in Aldous Huxley and Robert Ettinger. In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the ""Multivac"" series about a super-intelligent computer of the same name. Artificial Intelligence"" and ""Ex Machina"",  as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. ""Logic and Artificial Intelligence""."
3,Cosine Similarity,0.3422763214593095,0.3225,0.37283236994219654,"In computer science,  artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Or are there hard limits to what a machine can accomplish? Internet Encyclopedia of Philosophy. Hans Moravec, Ray Kurzweil and others have argued that it is technologically feasible to copy the brain directly into hardware and software and that such a simulation will be essentially identical to the original.The AI effect+Machines are already intelligent, but observers have failed to recognize it. Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. This lack of ""common knowledge"" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. Modern machine capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems (such as chess and Go), autonomously operating cars, intelligent routing in content delivery networks, and military simulations. Are intelligent machines dangerous? The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: ""Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In computer science,  artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Art+Artificial Intelligence has inspired numerous creative applications including its usage to produce visual art. Finally, a few ""emergent"" approaches look to simulating human intelligence extremely closely, and believe that anthropomorphic features like an artificial brain or simulated child development may someday reach a critical point where general intelligence emerges.Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. Many people concerned about risk from superintelligent AI also want to limit the use of artificial soldiers and drones. (A generic AI has difficulty discerning whether the ones alleged to be advocating violence are the councilmen or the demonstrators.) Can a machine intentionally cause harm? Microsoft is working on a project to develop a machine called ""Hanover"". Approaches include statistical methods, computational intelligence, and traditional symbolic AI. This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the hard problem of consciousness. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.The potential negative effects of AI and automation are a major issue for Andrew Yang's presidential campaign. Support for artificial intelligence is higher among men (with 47% approving) than women (35% approving). Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.Ray Kurzweil has used Moore's law (which describes the relentless exponential improvement in digital technology) to calculate that desktop computers will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045. ""robotics"" or ""machine learning""), the use of particular tools (""logic"" or artificial neural networks), or deep philosophical differences. The exhibition ""Thinking Machines: Art and Design in the Computer Age, 1959–1989"" at MoMA provides a good overview of the historical applications of AI for art, architecture, and design. Can it ""think""? While projects such as AlphaZero have succeeded in generating their own knowledge from scratch, many other machine learning projects require large training datasets. Different statistical learning techniques have different limitations; for example, basic HMM cannot model the infinite possible combinations of natural language. A number of researchers began to look into ""sub-symbolic"" approaches to specific AI problems. Cybernetics and brain simulation+In the 1940s and 1950s, a number of researchers explored the connection between neurobiology, information theory, and cybernetics."
